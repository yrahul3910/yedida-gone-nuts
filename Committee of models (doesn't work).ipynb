{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../../../Dodge/data/defect/'\n",
    "\n",
    "file_dic = {\"ivy\": [\"ivy-1.1.csv\", \"ivy-1.4.csv\", \"ivy-2.0.csv\"],\n",
    "            \"lucene\": [\"lucene-2.0.csv\", \"lucene-2.2.csv\", \"lucene-2.4.csv\"],\n",
    "            \"poi\": [\"poi-1.5.csv\", \"poi-2.0.csv\", \"poi-2.5.csv\", \"poi-3.0.csv\"],\n",
    "            \"synapse\": [\"synapse-1.0.csv\", \"synapse-1.1.csv\", \"synapse-1.2.csv\"],\n",
    "            \"velocity\": [\"velocity-1.4.csv\", \"velocity-1.5.csv\", \"velocity-1.6.csv\"],\n",
    "            \"camel\": [\"camel-1.0.csv\", \"camel-1.2.csv\", \"camel-1.4.csv\", \"camel-1.6.csv\"],\n",
    "            \"jedit\": [\"jedit-3.2.csv\", \"jedit-4.0.csv\", \"jedit-4.1.csv\", \"jedit-4.2.csv\", \"jedit-4.3.csv\"],\n",
    "            \"log4j\": [\"log4j-1.0.csv\", \"log4j-1.1.csv\", \"log4j-1.2.csv\"],\n",
    "            \"xalan\": [\"xalan-2.4.csv\", \"xalan-2.5.csv\", \"xalan-2.6.csv\", \"xalan-2.7.csv\"],\n",
    "            \"xerces\": [\"xerces-1.2.csv\", \"xerces-1.3.csv\", \"xerces-1.4.csv\"]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://gist.github.com/wassname/ce364fddfc8a025bfab4348cf5de852d\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        return K.mean(\n",
    "            K.binary_crossentropy(y_true, y_pred) * weights)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DL(frac):\n",
    "    n_layers = np.random.randint(1, 11)\n",
    "    n_units = np.random.randint(1, 21)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(n_units, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    weights = np.array([10./frac, 1.])\n",
    "    \n",
    "    model.compile(loss=weighted_categorical_crossentropy(weights), optimizer='sgd')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/30564015/how-to-generate-random-points-in-a-circular-distribution\n",
    "def fuzz_data(X, y, radii=(0., 1, .1)):\n",
    "    idx = np.where(y == 1)[0]\n",
    "    frac = len(idx) * 1. / len(y)\n",
    "    print('debug: weight =', 1./frac)\n",
    "    \n",
    "    fuzzed_x = []\n",
    "    fuzzed_y = []\n",
    "    \n",
    "    for row in X[idx]:\n",
    "        for i, r in enumerate(np.arange(*radii)):\n",
    "            for j in range(int((1./frac) / pow(np.sqrt(2), i))):\n",
    "                fuzzed_x.append([val - r for val in row])\n",
    "                fuzzed_x.append([val + r for val in row])\n",
    "                fuzzed_y.append(1)\n",
    "                fuzzed_y.append(1)\n",
    "    \n",
    "    return np.concatenate((X, np.array(fuzzed_x)), axis=0), np.concatenate((y, np.array(fuzzed_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def committee(filename):\n",
    "    paths = [os.path.join(base_path, file_name) for file_name in file_dic[filename]]\n",
    "    train_df = pd.concat([pd.read_csv(path) for path in paths[:-1]], ignore_index=True)\n",
    "    test_df = pd.read_csv(paths[-1])\n",
    "    \n",
    "    train_df, test_df = train_df.iloc[:, 3:], test_df.iloc[:, 3:]\n",
    "    train_size = train_df[\"bug\"].count()\n",
    "    df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    df['bug'] = df['bug'].apply(lambda x: 0 if x == 0 else 1)\n",
    "    \n",
    "    train_data = df.iloc[:train_size, :]\n",
    "    test_data = df.iloc[train_size:, :]\n",
    "    \n",
    "    X_train = np.array(train_data[train_data.columns[:-2]])\n",
    "    y_train = np.array(train_data['bug'])\n",
    "    X_test = np.array(test_data[test_data.columns[:-2]])\n",
    "    y_test = np.array(test_data['bug'])\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)\n",
    "    #X_train, y_train = fuzz_data(X_train, y_train)\n",
    "    \n",
    "    print('Fuzzed data. Number of samples =', len(X_train))\n",
    "    \n",
    "    frac = sum(y_train) * 1.0 / len(y_train)\n",
    "    \n",
    "    committee = [RandomForestClassifier(), RandomForestClassifier(), RandomForestClassifier(), \n",
    "                 KNeighborsClassifier(n_neighbors=2), KNeighborsClassifier(n_neighbors=3),\n",
    "                 KNeighborsClassifier(n_neighbors=4), KNeighborsClassifier(n_neighbors=5),\n",
    "                 LogisticRegression(), DL(frac), DL(frac), DL(frac), DL(frac), DL(frac), DL(frac), DL(frac),\n",
    "                 SVC(probability=True), GaussianNB()]\n",
    "    \n",
    "    pb = tqdm_notebook(total=len(committee))\n",
    "    for learner in committee:\n",
    "        if learner.__class__.__name__ == 'Sequential':\n",
    "            learner.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "        else:\n",
    "            learner.fit(X_train, y_train)\n",
    "        pb.update(1)\n",
    "        \n",
    "    print('Trained committee.')\n",
    "    \n",
    "    preds = []\n",
    "    for learner in committee:\n",
    "        if learner.__class__.__name__ == 'Sequential':\n",
    "            preds.append(learner.evaluate(X_val, y_val))\n",
    "        else:\n",
    "            preds.append(learner.score(X_val, y_val))\n",
    "    \n",
    "    print('Evaluated committee:', preds)\n",
    "        \n",
    "    test_preds = []\n",
    "    \n",
    "    pbar = tqdm_notebook(total=len(X_test))\n",
    "    for sample in X_test: \n",
    "        classified = False\n",
    "        most_conf = -1\n",
    "        most_conf_idx = -1\n",
    "        for index in reversed(np.argsort(preds)):            \n",
    "            prob = committee[index].predict_proba(sample.reshape(1, -1))[0][0]\n",
    "            \n",
    "            if prob > most_conf:\n",
    "                most_conf = prob\n",
    "                most_conf_idx = index\n",
    "            \n",
    "            if prob > 0.4 and prob < 0.5:\n",
    "                continue\n",
    "        \n",
    "        if not classified:\n",
    "            if committee[most_conf_idx].__class__.__name__ == 'Sequential':\n",
    "                test_preds.append(int(committee[most_conf_idx].predict_classes(sample.reshape(1,-1))))\n",
    "            else:\n",
    "                test_preds.append(committee[most_conf_idx].predict(sample.reshape(1,-1))[0])\n",
    "        pbar.update(1)\n",
    "    \n",
    "    test_preds = np.array(test_preds)\n",
    "    print(y_test)\n",
    "    print(test_preds.squeeze())\n",
    "    print(classification_report(y_test, test_preds.squeeze()))\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzed data. Number of samples = 264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933f1d7fc4c94f1e97fdf89e45d2af59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained committee.\n",
      "88/88 [==============================] - 0s 238us/step\n",
      "88/88 [==============================] - 0s 314us/step\n",
      "88/88 [==============================] - 0s 258us/step\n",
      "88/88 [==============================] - 0s 314us/step\n",
      "88/88 [==============================] - 0s 272us/step\n",
      "88/88 [==============================] - 0s 292us/step\n",
      "88/88 [==============================] - 0s 258us/step\n",
      "Evaluated committee: [0.7386363636363636, 0.7386363636363636, 0.7613636363636364, 0.7159090909090909, 0.7159090909090909, 0.7386363636363636, 0.75, 0.7727272727272727, nan, 14.81309647993608, 13.448060382496227, 14.073207161643289, 13.41886754469438, nan, nan, 0.75, 0.7954545454545454]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fb45444816439cbbbae6618b986b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=352), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       312\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.89       352\n",
      "   macro avg       0.44      0.50      0.47       352\n",
      "weighted avg       0.79      0.89      0.83       352\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "committee('ivy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
