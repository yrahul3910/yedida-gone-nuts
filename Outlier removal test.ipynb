{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# From https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "# and https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score, recall_score\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc(actual, preds, classes):\n",
    "    return roc_auc_score(label_binarize(actual, classes), label_binarize(preds, classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fpr(actual, preds):\n",
    "    tn, fp, fn, tp = confusion_matrix(actual, preds, labels=[0,1]).ravel()\n",
    "    fpr = fp * 1.0 / (tn + fp) if (tn + fp) != 0 else 0\n",
    "    \n",
    "    return fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(true):\n",
    "    total_true = float(len([i for i in true if i == 1]))\n",
    "    hit = 0.0\n",
    "    recall = []\n",
    "    for i in range(len(true)):\n",
    "        if true[i] == 1:\n",
    "            hit += 1\n",
    "        recall += [hit / total_true if total_true else 0.0]\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://gist.github.com/wassname/ce364fddfc8a025bfab4348cf5de852d\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        return K.mean(\n",
    "            K.binary_crossentropy(y_true, y_pred) * weights)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../../Dodge/data/defect/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dic = {\"ivy\": [\"ivy-1.1.csv\", \"ivy-1.4.csv\", \"ivy-2.0.csv\"],\n",
    "            \"lucene\": [\"lucene-2.0.csv\", \"lucene-2.2.csv\", \"lucene-2.4.csv\"],\n",
    "            \"poi\": [\"poi-1.5.csv\", \"poi-2.0.csv\", \"poi-2.5.csv\", \"poi-3.0.csv\"],\n",
    "            \"synapse\": [\"synapse-1.0.csv\", \"synapse-1.1.csv\", \"synapse-1.2.csv\"],\n",
    "            \"velocity\": [\"velocity-1.4.csv\", \"velocity-1.5.csv\", \"velocity-1.6.csv\"],\n",
    "            \"camel\": [\"camel-1.0.csv\", \"camel-1.2.csv\", \"camel-1.4.csv\", \"camel-1.6.csv\"],\n",
    "            \"jedit\": [\"jedit-3.2.csv\", \"jedit-4.0.csv\", \"jedit-4.1.csv\", \"jedit-4.2.csv\", \"jedit-4.3.csv\"],\n",
    "            \"log4j\": [\"log4j-1.0.csv\", \"log4j-1.1.csv\", \"log4j-1.2.csv\"],\n",
    "            \"xalan\": [\"xalan-2.4.csv\", \"xalan-2.5.csv\", \"xalan-2.6.csv\", \"xalan-2.7.csv\"],\n",
    "            \"xerces\": [\"xerces-1.2.csv\", \"xerces-1.3.csv\", \"xerces-1.4.csv\"]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inliers(X, y):\n",
    "    n_neighbors = int(np.sqrt(len(X)))\n",
    "    detector = LocalOutlierFactor(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    results = detector.fit_predict(X)\n",
    "    indices = np.where(results == 1)[0]\n",
    "    \n",
    "    return np.array(X)[indices], np.array(y)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_dataset(filename, metric='d2h', epochs=10, layers=4, draw_roc=False, weighted=False):\n",
    "    paths = [os.path.join(base_path, file_name) for file_name in file_dic[filename]]\n",
    "    train_df = pd.concat([pd.read_csv(path) for path in paths[:-1]], ignore_index=True)\n",
    "    test_df = pd.read_csv(paths[-1])\n",
    "    \n",
    "    train_df, test_df = train_df.iloc[:, 3:], test_df.iloc[:, 3:]\n",
    "    train_size = train_df[\"bug\"].count()\n",
    "    df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    df['bug'] = df['bug'].apply(lambda x: 0 if x == 0 else 1)\n",
    "    \n",
    "    train_data = df.iloc[:train_size, :]\n",
    "    test_data = df.iloc[train_size:, :]\n",
    "    \n",
    "    X_train = train_data[train_data.columns[:-2]]\n",
    "    y_train = train_data['bug']\n",
    "    X_test = test_data[test_data.columns[:-2]]\n",
    "    y_test = test_data['bug']\n",
    "    \n",
    "    X_train, y_train = get_inliers(X_train, y_train)\n",
    "    \n",
    "    frac = sum(y_train) * 1.0 / len(y_train)\n",
    "    if weighted:\n",
    "        weights = np.array([1., 1. / frac])\n",
    "    else:\n",
    "        weights = np.array([1., 1.])\n",
    "                \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_shape=(X_train.shape[1],), activation='relu', name='layer1'))\n",
    "    \n",
    "    for i in range(layers - 2):\n",
    "        model.add(Dense(20, activation='relu', name='layer'+str(i+2)))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid', name='layer'+str(layers)))\n",
    "    model.compile(loss=weighted_categorical_crossentropy(weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1, verbose=0, callbacks=[EarlyStopping(monitor='val_loss', patience=20, min_delta=0.0001)])\n",
    "    \n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    \n",
    "    if metric == 'fpr':\n",
    "        metric_ = get_fpr(y_test, y_pred)\n",
    "    elif metric == 'recall':\n",
    "        metric_ = recall_score(y_test, y_pred)\n",
    "    elif metric == 'auc':\n",
    "        metric_ = get_auc(y_test, y_pred, classes=[0,1])\n",
    "    \n",
    "    if draw_roc:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "        print('AUC =', auc(fpr, tpr))\n",
    "        print(metric, '=', metric_)\n",
    "        plt.plot(fpr, tpr, color='darkorange')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    \n",
    "    return history, metric_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivy\n",
      "===\n",
      "fpr - 0.15 0.1\n",
      "recall - 0.24 0.18\n",
      "auc - 0.56 0.55\n",
      "\n",
      "lucene\n",
      "======\n",
      "fpr - 0.44 0.43\n",
      "recall - 0.6 0.59\n",
      "auc - 0.58 0.58\n",
      "\n",
      "poi\n",
      "===\n",
      "fpr - 0.15 0.11\n",
      "recall - 0.37 0.31\n",
      "auc - 0.62 0.64\n",
      "\n",
      "synapse\n",
      "=======\n",
      "fpr - 0.11 0.07\n",
      "recall - 0.18 0.15\n",
      "auc - 0.55 0.56\n",
      "\n",
      "velocity\n",
      "========\n",
      "fpr - 0.9 0.91\n",
      "recall - 0.89 0.9\n",
      "auc - 0.51 0.51\n",
      "\n",
      "camel\n",
      "=====\n",
      "fpr - 0.04 0.03\n",
      "recall - 0.1 0.06\n",
      "auc - 0.54 0.53\n",
      "\n",
      "jedit\n",
      "=====\n",
      "fpr - 0.19 0.19\n",
      "recall - 0.31 0.36\n",
      "auc - 0.58 0.6\n",
      "\n",
      "log4j\n",
      "=====\n",
      "fpr - 0.25 0.22\n",
      "recall - 0.29 0.25\n",
      "auc - 0.54 0.55\n",
      "\n",
      "xalan\n",
      "=====\n",
      "fpr - 0.05 0.09\n",
      "recall - 0.25 0.24\n",
      "auc - 0.62 0.62\n",
      "\n",
      "xerces\n",
      "======\n",
      "fpr - 0.01 0.0\n",
      "recall - 0.05 0.03\n",
      "auc - 0.52 0.52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in file_dic.keys():\n",
    "    print(dataset)\n",
    "    print('=' * len(dataset))\n",
    "    for metric in ['fpr', 'recall', 'auc']:\n",
    "        values = []\n",
    "        for i in range(20):\n",
    "            _, metric_ = run_on_dataset(filename=dataset, metric=metric, epochs=10, layers=4)\n",
    "            values.append(metric_)\n",
    "        \n",
    "        print(metric, '-', np.round(np.mean(values), 2), np.round(np.median(values), 2))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
